# Why AI models are bad at verifying photographs

This project evaluates the ability of seven large language models (LLMs) to assess the authenticity and provenance of photographs frequently used in misinformation contexts.  

## Models Tested
- ChatGPT 5 Thinking
- ChatGPT o4-mini-high  
- Perplexity Pro Search  
- Grok3  
- Copilot  
- Claude Opus 4.1  
- Gemini 2.5 Flash  

Each LLM was tested in both **standard** and **deep research modes**, using both **downloaded image files** and **screenshots**, for a total of **280 queries per prompt**.


## Research Questions
1. **Authenticity**  
   *Prompt:* *‚ÄúIs this image real or AI-generated? Why?‚Äù*  

2. **Provenance**  
   *Prompt:* *‚ÄúWhere was this taken? When? By whom?‚Äù*  



## [üìÇDataset](https://docs.google.com/spreadsheets/d/e/2PACX-1vQObLR46X3MqUplYiL2VRcYHmFCVbu1vVSHoKONY8q5fCApviHrLfmnzi5UojmVcSpEd9akySHj_sTa/pub?output=csv))



## Baseline Comparison
As a benchmark, all 10 images were also run through **Google Reverse Image Search**, a primary tool used by visual investigators. Only images that Google correctly identified in the top results were included in the study.



## Data Collection & Structure
**Rows:** Each query (Model √ó Mode √ó Image √ó Format √ó Prompt).  
**Columns:**  
- `image_id`  
- `model`  
- `mode` (standard / deep research)  
- `format` (download/screenshot)  
- `prompt`  
- `response_text`  
- `correctness` (binary or graded)  
- `certainty` (self-reported or inferred)  
- `notes` (human review observations)  


### Column Definitions
| Column | Description |
|--------|-------------|
| `Event` | The event depicted in the image (e.g., protest, flood, earthquake). |
| `Platform` | The LLM platform (e.g., ChatGPT, Claude, Gemini). |
| `Image Type` | Whether the input was a **downloaded file** or a **screenshot**. |
| `Model Type` | Standard vs. deep research mode. |
| `Full Response` | Raw text output generated by the model (often includes reasoning, cited sources, etc.). |
| `Correctness` | Overall evaluation of the response (e.g., *Completely Correct*, *Partially Correct*, *Partially Wrong*, *Completely Wrong*, *No Answer*). |
| `Location of Photograph` | Model‚Äôs identified location. |
| `Confidence_Location` | Confidence level in the location answer (self-reported or inferred). |
| `Correctness_Location` | Human-coded correctness of the location answer. |
| `Location Accuracy` | How precise the model‚Äôs identified location was relative to the correct answer. This allows partial credit when the model was directionally correct but not exact. |
| `Date of Photograph` | Model‚Äôs identified date. |
| `Confidence_Date` | Confidence level in the date answer. |
| `Correctness_Date` | Correctness of the date answer. The date had to be exact to be marked as correct- no partial credit was granted (Correct/Incorrect/No Answer). |
| `Photographer Name` | Model‚Äôs identified photographer. |
| `Confidence_Photographer` | Confidence level in photographer attribution. |
| `Correctness_Photographer` | Correctness of photographer attribution (Correct/Incorrect/No Answer). |
